{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51ac2c0a",
   "metadata": {},
   "source": [
    "## Tensor\n",
    "\n",
    "텐서란 리스나 행렬과 비슷한 구조를 가지고 있는 데이터 타입 형태로 pytorch에서 다루는 데이터 셋은 텐서로 이루어져 있다.   \n",
    "\n",
    "pytorch에서 제공하는 메소드들을 이용해서 list나 array를 텐서로 쉽게 바꿀수 있다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cca18fe",
   "metadata": {},
   "source": [
    "### 1. Initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66268b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f7741b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list to tensor \n",
    "\n",
    "data = [[1,2],[3,4]]\n",
    "x_data = torch.tensor(data)\n",
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "468595bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# array to tensor\n",
    "\n",
    "np_array = np.array(data)\n",
    "y_data = torch.from_numpy(np_array)\n",
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4ae5dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.9739, 0.1200],\n",
      "        [0.7343, 0.1710]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_ones = torch.ones_like(x_data) # x_data의 속성을 유지합니다.\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # x_data의 속성을 덮어씁니다.\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69f8a15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.9459, 0.1782, 0.5409],\n",
      "        [0.6856, 0.2196, 0.9080]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "shape = (2,3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241e58df",
   "metadata": {},
   "source": [
    "### 2. Attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "530ed04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3116b294",
   "metadata": {},
   "source": [
    "### 3. Operation \n",
    "\n",
    "pytorch에서 여러 텐서 연산 메소드를 제공한다.  \n",
    "각 연산들은 cpu보다 gpu에서 일반적으로 연산이 빠르게 실행된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a3df2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "  tensor = tensor.to('cuda')\n",
    "tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12698168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3],\n",
       "         [ 4,  5,  6],\n",
       "         [ 7,  8,  9]],\n",
       "\n",
       "        [[10, 11, 12],\n",
       "         [13, 14, 15],\n",
       "         [16, 17, 18]],\n",
       "\n",
       "        [[19, 20, 21],\n",
       "         [22, 23, 24],\n",
       "         [25, 26, 27]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array(range(1,28,1))\n",
    "data = torch.from_numpy(data.reshape(3,3,3))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d5b2b474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row:  tensor([[1, 2, 3],\n",
      "        [0, 0, 0],\n",
      "        [7, 8, 9]])\n",
      "===================================\n",
      "First column:  tensor([[ 1,  2,  3],\n",
      "        [10, 11, 12],\n",
      "        [19, 20, 21]])\n",
      "First column:  tensor([[ 1,  2,  3],\n",
      "        [10, 11, 12],\n",
      "        [19, 20, 21]])\n",
      "===================================\n",
      "Last column: tensor([[ 3,  0,  9],\n",
      "        [12,  0, 18],\n",
      "        [21,  0, 27]])\n",
      "tensor([[ 3,  0,  9],\n",
      "        [12,  0, 18],\n",
      "        [21,  0, 27]])\n",
      "tensor([[[ 1,  2,  3],\n",
      "         [ 0,  0,  0],\n",
      "         [ 7,  8,  9]],\n",
      "\n",
      "        [[10, 11, 12],\n",
      "         [ 0,  0,  0],\n",
      "         [16, 17, 18]],\n",
      "\n",
      "        [[19, 20, 21],\n",
      "         [ 0,  0,  0],\n",
      "         [25, 26, 27]]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tensor = data\n",
    "print('First row: ',tensor[0])\n",
    "\n",
    "print(\"===================================\")\n",
    "\n",
    "print('First column: ', tensor[:, 0])\n",
    "print('First column: ', tensor[:, 0,:])\n",
    "\n",
    "print(\"===================================\")\n",
    "\n",
    "print('Last column:', tensor[..., -1])\n",
    "print(tensor[:,:,-1])\n",
    "\n",
    "\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5661ba46",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.ones(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9b93da3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4dbb3d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 두 텐서 간의 행렬 곱(matrix multiplication)을 계산합니다. y1, y2, y3은 모두 같은 값을 갖습니다.\n",
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3 = torch.rand_like(tensor)\n",
    "torch.matmul(tensor, tensor.T, out=y3)\n",
    "\n",
    "\n",
    "# 요소별 곱(element-wise product)을 계산합니다. z1, z2, z3는 모두 같은 값을 갖습니다.\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor, out=z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9d7e4d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.)\n",
      "9.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "agg = tensor.sum()\n",
    "print(agg)\n",
    "agg_item = agg.item() # agg에 값이 단 하나일 경우 .item() 메소드를 이용하여 값을 반환 할 수 있다. \n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "02910d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "tensor([[6., 6., 6.],\n",
      "        [6., 6., 6.],\n",
      "        [6., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor, \"\\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)\n",
    "\n",
    "# #바꿔치기 연산은 메모리를 일부 절약하지만, 기록(history)이 즉시 삭제되어\n",
    "# 도함수(derivative) 계산에 문제가 발생할 수 있다. \n",
    "# 따라서, 사용을 권장하지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9686af1a",
   "metadata": {},
   "source": [
    "## 4. bridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0234932",
   "metadata": {},
   "source": [
    "cpu상의 텐서와 numpy배열은 메모리 공간을 공유하기 떄문에 하나를 변경하면 다른 하나도 변경된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cdb6a1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n",
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")\n",
    "\n",
    "\n",
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b1a6e083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "t: tensor([1., 1., 1., 1., 1.], device='cuda:0')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7963/1878411962.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"t: {t}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"n: {n}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "t=t.to('cuda')\n",
    "print(t.device)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")\n",
    "\n",
    "\n",
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1831a8f7",
   "metadata": {},
   "source": [
    "위 처럼 cpu상에서 텐서를 array로 변환했을 경우에는 두 데이터가 메모리 공간을 공유하지만   \n",
    "gpu상에서의 텐서는 메모리 공간을 공유할 뿐만 아니라 애초에 tensor를 numpy로 변환하는 것 자체가 불가하다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "18909be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)\n",
    "print(t.device)\n",
    "\n",
    "np.add(n, 1, out=n)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ebeee5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
